{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aafec47-0c66-4bf4-84c8-6e49c7be1f7d",
   "metadata": {},
   "source": [
    "# TensorFlow, Keras und deep learning, ohne Doktortitel\n",
    "__verfasst von einem Google-Mitarbeiter__  \n",
    "\n",
    "Original siehe\n",
    "* https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist#0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66cf36-dda9-462f-84b3-fdf1812494e6",
   "metadata": {},
   "source": [
    "## 1. Übersicht\n",
    "\n",
    "In diesem Codelab lernen Sie, wie Sie ein neuronales Netzwerk aufbauen und trainieren, das handgeschriebene Ziffern erkennt. Während Sie Ihr neuronales Netzwerk verbessern, um eine Genauigkeit von 99 % zu erreichen, werden Sie auch die Werkzeuge kennenlernen, die Deep-Learning-Profis verwenden, um ihre Modelle effizient zu trainieren.\n",
    "\n",
    "Dieses Codelab verwendet den MNIST-Datensatz, eine Sammlung von 60.000 beschrifteten Ziffern, die Generationen von Doktoranden fast zwei Jahrzehnte lang beschäftigt hat. Sie werden das Problem mit weniger als 100 Zeilen Python / TensorFlow-Code lösen.\n",
    "\n",
    "#### Was Sie lernen werden\n",
    "* Was ist ein neuronales Netzwerk und wie trainiert man es?\n",
    "* Wie man ein einfaches neuronales Netzwerk mit 1 Schicht mit tf.keras aufbaut\n",
    "* Wie man weitere Schichten hinzufügt\n",
    "* Wie man einen Lernratenplan einrichtet\n",
    "* Wie man neuronale Netze mit Faltung aufbaut\n",
    "* Wie man Regularisierungstechniken verwendet: Dropout, Batch-Normalisierung\n",
    "* Was ist Overfitting?   \n",
    "\n",
    "#### Was Sie brauchen\n",
    "* Nur einen Browser. Dieser Workshop kann vollständig in Google Colab durchgeführt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd855a46-9902-4a84-b55c-e832ae88d90f",
   "metadata": {},
   "source": [
    "## 2. Google Colaboratory quick start\n",
    "siehe https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/colab_intro.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5bea3d-f203-4a22-a6c9-043da0e6faa9",
   "metadata": {},
   "source": [
    "## 3. Trainieren eines neuronalen Netzes\n",
    "Zuerst werden wir ein neuronales Netz trainieren. Bitte öffnen Sie das unten stehende Notizbuch und gehen Sie alle Zellen durch. Achten Sie noch nicht auf den Code, wir werden später damit beginnen, ihn zu erklären.\n",
    "\n",
    "<img src=\"images/teke00.png\" width=\"20\" height=\"20\">  [keras_01_mnist.ipynb](keras_01_mnist.ipynb)\n",
    "\n",
    "Konzentrieren Sie sich beim Ausführen des Notizbuchs auf die Visualisierungen. Siehe unten für Erklärungen.\n",
    "\n",
    "#### Trainingsdaten\n",
    "Wir haben einen Datensatz handgeschriebener Ziffern, die so beschriftet wurden, dass wir wissen, wofür jedes Bild steht, d.h. eine Zahl zwischen 0 und 9. Im Notizbuch sehen Sie einen Auszug davon:\n",
    "\n",
    "<img src=\"images/teke02.png\" width=\"800\">\n",
    "\n",
    "Das neuronale Netz, das wir aufbauen werden, klassifiziert die handgeschriebenen Ziffern in ihre 10 Klassen (0, ..., 9). Es tut dies auf der Grundlage interner Parameter, die einen korrekten Wert haben müssen, damit die Klassifizierung gut funktioniert. Dieser \"richtige Wert\" wird durch einen Trainingsprozess erlernt, der einen \"markierten Datensatz\" mit Bildern und den dazugehörigen richtigen Antworten erfordert.\n",
    "\n",
    "Wie lässt sich feststellen, ob das trainierte neuronale Netz gut funktioniert oder nicht? Die Verwendung des Trainingsdatensatzes zum Testen des Netzes wäre ein Betrug. Es hat diesen Datensatz während des Trainings bereits mehrfach gesehen und ist mit Sicherheit sehr leistungsfähig darin. Wir benötigen einen weiteren beschrifteten Datensatz, den es während des Trainings noch nie gesehen hat, um die Leistung (performance) des Netzes in der \"realen Welt\" zu bewerten. Dieser wird als \"Validierungsdatensatz\" (validation dataset) bezeichnet.\n",
    "\n",
    "<p style='background :#eeee88' >  \n",
    "Dieser Datensatz enthält 50.000 Ziffern für das Training. Bei jeder Iteration wird ein <b>\"Batch\"</b> (Stapel) von 128 Ziffern in die Trainingsschleife eingegeben, so dass das System nach 391 Iterationen alle Trainingsziffern einmal gesehen hat. Wir nennen dies eine <b>\"Epoche\"</b>. Insgesamt werden bei diesem Training 10 Epochen durchlaufen.  \n",
    "Außerdem gibt es 10.000 separate <b>\"validation\"</b>-digits (Ziffern zur Überprüfung) zum Testen der Performance des Modells.\n",
    "</p>\n",
    "\n",
    "#### Training\n",
    "Mit fortschreitendem Training, d. h. mit jedem Stapel von Trainingsdaten, werden die internen Modellparameter aktualisiert, und das Modell wird bei der Erkennung handgeschriebener Ziffern immer besser. Sie können dies in der Trainingskurve sehen:\n",
    "\n",
    "<img src=\"images/teke03.png\" width=\"800\">\n",
    "\n",
    "Auf der rechten Seite ist die \"Genauigkeit\" einfach der Prozentsatz der richtig erkannten Ziffern. Sie steigt mit fortschreitendem Training an, was gut ist.\n",
    "\n",
    "Auf der linken Seite sehen wir den \"Verlust\". Um das Training zu steuern, definieren wir eine \"Verlustfunktion\", die angibt, wie schlecht das System die Ziffern erkennt, und versuchen, sie zu minimieren. Sie sehen hier, dass der Verlust sowohl bei den Trainings- als auch bei den Validierungsdaten mit fortschreitendem Training abnimmt: Das ist gut. Es bedeutet, dass das neuronale Netz lernt.\n",
    "\n",
    "Die X-Achse stellt die Anzahl der \"Epochen\" oder Iterationen durch den gesamten Datensatz dar.\n",
    "\n",
    "#### Predictions (Vorhersagen)\n",
    "Wenn das Modell trainiert ist, können wir es verwenden, um handgeschriebene Ziffern zu erkennen. Die nächste Visualisierung zeigt, wie gut es bei einigen Ziffern aus lokalen Schriftarten (erste Zeile) und dann bei den 10.000 Ziffern des Validierungsdatensatzes abschneidet. Die vorhergesagte Klasse erscheint unter jeder Ziffer, in rot, wenn sie falsch war.\n",
    "\n",
    "\n",
    "<img src=\"images/teke04.png\" width=\"800\">\n",
    "\n",
    "\n",
    "Wie Sie sehen können, ist dieses anfängliche Modell nicht sehr gut, erkennt aber dennoch einige Ziffern richtig. Die endgültige Validierungsgenauigkeit liegt bei etwa 90 %, was für das einfache Modell, mit dem wir beginnen, nicht so schlecht ist, aber immer noch bedeutet, dass es 1000 von 10.000 Validierungsziffern nicht erkennt. Das ist weit mehr, als angezeigt werden kann, weshalb es so aussieht, als wären alle Antworten falsch (rot).\n",
    "\n",
    "Tensoren\n",
    "Daten werden in Matrizen gespeichert. Ein 28x28 Pixel großes Graustufenbild passt in eine zweidimensionale 28x28-Matrix. Für ein Farbbild benötigen wir jedoch mehr Dimensionen. Es gibt 3 Farbwerte pro Pixel (Rot, Grün, Blau), also wird eine dreidimensionale Tabelle mit den Dimensionen [28, 28, 3] benötigt. Und um einen Stapel von 128 Farbbildern zu speichern, ist eine vierdimensionale Tabelle mit den Abmessungen [128, 28, 28, 3] erforderlich.\n",
    "\n",
    "Diese mehrdimensionalen Tabellen werden __\"Tensoren\"__ genannt, und die Liste ihrer Dimensionen ist ihre __\"Shape\" (Form)__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd9c23d-e29a-4d19-9a89-b9aeaf298f1f",
   "metadata": {},
   "source": [
    "## 4. Neuronale Netze auf den Punkt gebracht\n",
    "\n",
    "Wenn Ihnen alle fettgedruckten Begriffe im nächsten Abschnitt bereits bekannt sind, können Sie zur nächsten Übung übergehen. Wenn Sie gerade erst mit Deep Learning beginnen, dann herzlich willkommen und lesen Sie bitte weiter.\n",
    "<p style='background :#eeee88' > \n",
    "    Ein neuronales Netzwerk besteht aus mehreren <b>layers</b> (Schichten) von <b>Neuronen</b>. Für die Bildklassifizierung können dies <b>dense</b> (dichte) oder, was häufiger der Fall ist, <b>convolutional layers</b> (Faltungsschichten) sein. Sie werden in der Regel mit der <b>relu</b>-Aktivierungsfunktion verknüpft. Die letzte Schicht verwendet so viele Neuronen, wie es Klassen gibt, und wird mit der <b>Softmax</b>-Aktivierungsfunktion verknüpft. Für die Klassifizierung ist die <b>cross-entropy</b> (Kreuzentropie) die am häufigsten verwendete <b>loss function</b> (Verlustfunktion), bei der die mit <b>one hot</b> (einem Punkt) kodierten <b>labels</b> (Kennzeichnungen d. h. die richtigen Antworten) mit den vom neuronalen Netz vorhergesagten Wahrscheinlichkeiten verglichen werden. Um den Verlust zu minimieren, wählt man am besten einen Optimierer mit Momentum, z. B. <b>Adam</b>, und trainiert mit <b>batches</b> (Stapeln) von Trainingsbildern und Etiketten.\n",
    "</p>\n",
    "<img src=\"images/teke05.png\" width=\"800\">\n",
    "\n",
    "Für Modelle, die aus einer Abfolge von Schichten bestehen, bietet Keras die Sequential API an. Zum Beispiel kann ein Bildklassifikator mit drei dichten Schichten in Keras wie folgt geschrieben werden:\n",
    "\n",
    "<img src=\"images/teke05b.png\" width=\"800\">\n",
    "\n",
    "#### A single dense layer (Eine einzige dichte Schicht)\n",
    "\n",
    "Handgeschriebene Ziffern im MNIST-Datensatz sind 28x28 Pixel große Graustufenbilder. Der einfachste Ansatz für ihre Klassifizierung besteht darin, die 28x28=784 Pixel als Eingaben für ein neuronales Netz mit einer Schicht zu verwenden.\n",
    "\n",
    "<img src=\"images/teke06.png\" width=\"800\">\n",
    "\n",
    "Jedes \"__Neuron__\" in einem neuronalen Netz bildet eine gewichtete Summe aller Eingaben, fügt eine Konstante hinzu, die als \"Bias\" bezeichnet wird, und leitet das Ergebnis dann durch eine nichtlineare __\"activation function\"__ (Aktivierungsfunktion) weiter. Die __\"weights\"__ (Gewichte) und __\"biases\"__ (Verzerrungen) sind Parameter, die durch Training bestimmt werden. Sie werden zunächst mit Zufallswerten initialisiert.\n",
    "\n",
    "Die obige Abbildung zeigt ein neuronales Netz mit 1 Schicht und 10 Ausgangsneuronen, da wir die Ziffern in 10 Klassen (0 bis 9) einteilen wollen.\n",
    "\n",
    "#### Mit einer Matrixmultiplikation\n",
    "\n",
    "Hier sehen Sie, wie eine Schicht eines neuronalen Netzes, die eine Sammlung von Bildern verarbeitet, durch eine Matrixmultiplikation dargestellt werden kann:\n",
    "\n",
    "<img src=\"images/teke07.gif\" width=\"800\">\n",
    "\n",
    "Anhand der ersten Spalte der Gewichtungen in der Gewichtungsmatrix W wird die gewichtete Summe aller Pixel des ersten Bildes berechnet. Diese Summe entspricht dem ersten Neuron. Mit der zweiten Spalte der Gewichte machen wir das Gleiche für das zweite Neuron und so weiter bis zum 10. Neuron. Dann können wir den Vorgang für die restlichen 99 Bilder wiederholen. Wenn wir X als die Matrix bezeichnen, die unsere 100 Bilder enthält, sind alle gewichteten Summen für unsere 10 Neuronen, die auf 100 Bildern berechnet werden, einfach X.W, eine Matrixmultiplikation.\n",
    "\n",
    "Jedes Neuron muss nun seinen Bias (eine Konstante) addieren. Da wir 10 Neuronen haben, haben wir 10 Bias-Konstanten. Wir nennen diesen Vektor von 10 Werten b. Er muss zu jeder Zeile der zuvor berechneten Matrix hinzugefügt werden. Mit Hilfe eines kleinen Zaubers namens \"Broadcasting\" schreiben wir dies mit einem einfachen Pluszeichen.\n",
    "\n",
    "<p style='background :#eeee88' >  \n",
    "<b>\"Broadcasting\"</b>  ist ein Standardtrick, der in Python und numpy, der Bibliothek für wissenschaftliche Berechnungen, verwendet wird. Er erweitert die Funktionsweise normaler Operationen auf Matrizen mit inkompatiblen Dimensionen. \"Broadcasting add\" bedeutet: \"Wenn Sie zwei Matrizen addieren wollen, aber das nicht können, weil ihre Dimensionen nicht kompatibel sind, versuchen Sie, die kleinere der Matrizen so oft wie nötig zu vervielfältigen, damit es funktioniert.\"    \n",
    "</p>\n",
    "\n",
    "Schließlich wenden wir eine Aktivierungsfunktion an, z. B. \"Softmax\" (siehe unten), und erhalten die Formel, die ein neuronales Netz mit einer Schicht beschreibt, das auf 100 Bilder angewendet wird:\n",
    "\n",
    "<img src=\"images/teke08.png\" width=\"800\">\n",
    "\n",
    "\n",
    "#### In Keras\n",
    "Mit High-Level-Bibliotheken für neuronale Netze wie Keras brauchen wir diese Formel nicht zu implementieren. Es ist jedoch wichtig zu verstehen, dass eine Schicht eines neuronalen Netzes nur eine Reihe von Multiplikationen und Additionen ist. In Keras würde eine \"dense layer\" (dichte Schicht) wie folgt geschrieben werden:\n",
    "\n",
    "<img src=\"images/teke08b.png\" width=\"800\">\n",
    "\n",
    "#### Tiefer gehen\n",
    "\n",
    "Es ist trivial, Schichten eines neuronalen Netzes zu verketten. Die erste Schicht berechnet gewichtete Summen von Pixeln. Nachfolgende Schichten berechnen gewichtete Summen der Ausgaben der vorherigen Schichten.\n",
    "\n",
    "<img src=\"images/teke09.png\" width=\"800\">\n",
    "\n",
    "Der einzige Unterschied, abgesehen von der Anzahl der Neuronen, ist die Wahl der Aktivierungsfunktion.\n",
    "\n",
    "#### Aktivierungsfunktionen: relu, softmax und sigmoid\n",
    "\n",
    "Normalerweise verwenden Sie die Aktivierungsfunktion \"relu\" für alle Schichten außer der letzten. Die letzte Schicht in einem Klassifikator würde die Aktivierungsfunktion \"softmax\" verwenden.\n",
    "\n",
    "<img src=\"images/teke10.png\" width=\"800\">\n",
    "Auch hier berechnet ein \"Neuron\" eine gewichtete Summe aller seiner Eingaben, fügt einen Wert hinzu, der \"Bias\" genannt wird, und leitet das Ergebnis durch die Aktivierungsfunktion.\n",
    "\n",
    "Die beliebteste Aktivierungsfunktion heißt __\"RELU\"__ für Rectified Linear Unit. Es handelt sich um eine sehr einfache Funktion, wie Sie in der obigen Grafik sehen können.\n",
    "\n",
    "Die traditionelle Aktivierungsfunktion in neuronalen Netzen war das __\"sigmoid\"__, aber es hat sich gezeigt, dass die \"RELU\" fast überall bessere Konvergenzeigenschaften hat und heute bevorzugt wird.\n",
    "\n",
    "<img src=\"images/teke11.png\" width=\"500\">\n",
    "\n",
    "Softmax-Aktivierung für die Klassifizierung\n",
    "\n",
    "Die letzte Schicht unseres neuronalen Netzes hat 10 Neuronen, weil wir handgeschriebene Ziffern in 10 Klassen (0,...9) klassifizieren wollen. Es soll 10 Zahlen zwischen 0 und 1 ausgeben, die die Wahrscheinlichkeit darstellen, dass diese Ziffer eine 0, eine 1, eine 2 usw. ist. Zu diesem Zweck wird auf der letzten Schicht eine Aktivierungsfunktion namens __\"softmax\"__ verwendet.\n",
    "\n",
    "Die Anwendung von __softmax__ auf einen Vektor erfolgt, indem der Exponentialwert jedes Elements genommen und der Vektor dann normalisiert wird, typischerweise durch Division durch seine \"L1\"-Norm (d. h. die Summe der absoluten Werte), so dass die normalisierten Werte sich zu 1 addieren und als Wahrscheinlichkeiten interpretiert werden können.\n",
    "\n",
    "Die Ausgabe der letzten Schicht vor der Aktivierung wird manchmal als \"Logits\" bezeichnet. Wenn dieser Vektor L = [L0, L1, L2, L3, L4, L5, L6, L7, L8, L9] ist, dann:\n",
    "\n",
    "<img src=\"images/teke12.png\" width=\"500\">\n",
    "\n",
    "<img src=\"images/teke12b.gif\" width=\"500\">\n",
    "\n",
    "<p style='background :#eeee88' >  \n",
    "Warum wird \"softmax\" softmax genannt? Die Exponentialfunktion ist eine steil ansteigende Funktion. Sie erhöht die Unterschiede zwischen den Neuronenausgängen. Wenn Sie dann den Vektor normalisieren, wird das größte Element, das die Norm dominiert, auf einen Wert nahe 1 normalisiert, während alle anderen Elemente durch einen großen Wert geteilt und auf einen Wert nahe 0 normalisiert werden. Der resultierende Vektor zeigt deutlich, welches die Gewinnerklasse ist, das \"max\", behält aber die ursprüngliche relative Reihenfolge seiner Werte bei, daher das \"soft\".  \n",
    "</p>\n",
    "\n",
    "#### Cross-entropy loss (Kreuzentropieverlust)\n",
    "\n",
    "Da unser neuronales Netz nun Vorhersagen aus den Eingabebildern erstellt, müssen wir messen, wie gut diese sind, d. h. den Abstand zwischen dem, was das Netz uns sagt, und den korrekten Antworten, oft als \"Labels\" bezeichnet. Denken Sie daran, dass wir für alle Bilder des Datensatzes korrekte Bezeichnungen haben.\n",
    "\n",
    "Jeder Abstand kann verwendet werden, aber bei Klassifizierungsproblemen ist der so genannte \"Cross-entropy loss\" (Kreuzentropieabstand) am [effektivsten](https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/). Wir nennen dies unsere Fehler- oder __\"loss\"__ (Verlust)-Funktion:\n",
    "\n",
    "<img src=\"images/teke13.png\" width=\"800\">\n",
    "\n",
    "<p style='background :#eeee88' > \n",
    "Die <b>\"One-hot\"</b>-Kodierung bedeutet, dass man die Bezeichnung \"dies ist die Ziffer 3\" durch einen Vektor von 10 Werten darstellt, die alle Nullen sind, mit Ausnahme des dritten Wertes, der 1 ist. Dieser Vektor repräsentiert eine 100%ige Wahrscheinlichkeit, dass es sich um die \"Ziffer 3\" handelt. Unser neuronales Netz gibt seine Vorhersagen ebenfalls als einen Vektor von 10 Wahrscheinlichkeitswerten aus. Sie sind leicht zu vergleichen.\n",
    "</p>\n",
    "\n",
    "#### Gradient descent - Gradientenabstieg\n",
    "\n",
    "Das \"Training\" des neuronalen Netzes bedeutet, dass die Trainingsbilder und -etiketten (labels) verwendet werden, um die Gewichte und biases (Verzerrungen) so anzupassen, dass die cross-entropy loss function (Kreuzentropieverlustfunktion) minimiert wird. Das funktioniert folgendermaßen.\n",
    "\n",
    "Die cross entropy (Kreuzentropie) ist eine Funktion der weights (Gewichte), der biases (Verzerrungen), der Pixel des Trainingsbildes und seiner bekannten Klasse.\n",
    "\n",
    "Wenn wir die partiellen Ableitungen der cross-entropy (Kreuzentropie) relativ zu allen Gewichten und allen Verzerrungen berechnen, erhalten wir einen \"Gradienten\", der für ein bestimmtes Bild, ein Label und den aktuellen Wert der Gewichte und Verzerrungen berechnet wird. Denken Sie daran, dass wir Millionen von Gewichten und Verzerrungen haben können, so dass die Berechnung des Gradienten nach einer Menge Arbeit klingt. Glücklicherweise macht TensorFlow das für uns. Die mathematische Eigenschaft eines Gradienten ist, dass er \"nach oben\" zeigt. Da wir dorthin gehen wollen, wo die cross-entropy (Kreuzentropie) niedrig ist, gehen wir in die entgegengesetzte Richtung. Wir aktualisieren die Gewichte und Verzerrungen um einen Bruchteil des Gradienten. Das Gleiche wiederholen wir dann mit den nächsten Stapeln von Trainingsbildern und -beschriftungen in einer Trainingsschleife. Hoffentlich konvergiert dies zu einem Punkt, an dem die cross-entropy (Kreuzentropie) minimal ist, obwohl nichts garantiert, dass dieses Minimum eindeutig ist.\n",
    "\n",
    "<img src=\"images/teke14.png\" width=\"800\">\n",
    "\n",
    "<p style='background :#eeee88' > \n",
    "    <b>\"Lernrate\"</b>: Man kann nicht bei jeder Iteration die Gewichte und Verzerrungen um die gesamte Länge des Gradienten aktualisieren. Das wäre so, als würde man mit Siebenmeilenstiefeln versuchen, den Grund eines Tals zu erreichen. Sie würden von einer Seite des Tals zur anderen springen. Um den Grund zu erreichen, müssen Sie kleinere Schritte machen, d.h. nur einen Bruchteil des Gradienten verwenden, normalerweise im Bereich von 1/1000. Dieser Bruchteil wird als \"Lernrate\" bezeichnet.\n",
    "</p>\n",
    "\n",
    "#### Mini-Batching und Momentum\n",
    "\n",
    "Sie können Ihren Gradienten auch nur für ein einziges Beispielbild berechnen und die Gewichte und Verzerrungen sofort aktualisieren. Wenn Sie dies jedoch für einen Stapel von z. B. 128 Bildern tun, erhalten Sie einen Gradienten, der die von den verschiedenen Beispielbildern auferlegten Beschränkungen besser darstellt und daher wahrscheinlich schneller zur Lösung konvergiert. Die Größe des Mini-Batch ist ein einstellbarer Parameter.\n",
    "\n",
    "Diese Technik, die manchmal auch als \"stochastischer Gradientenabstieg\" bezeichnet wird, hat noch einen weiteren, eher pragmatischen Vorteil: Die Arbeit mit Stapeln bedeutet auch die Arbeit mit größeren Matrizen, und diese lassen sich in der Regel auf GPUs und TPUs leichter optimieren.\n",
    "\n",
    "Die Konvergenz kann allerdings immer noch ein wenig chaotisch sein und sogar anhalten, wenn der Gradientenvektor nur Nullen enthält. Bedeutet das, dass wir ein Minimum gefunden haben? Nicht immer. Eine Gradientenkomponente kann sowohl bei einem Minimum als auch bei einem Maximum null sein. Wenn bei einem Gradientenvektor mit Millionen von Elementen alle Nullen sind, ist die Wahrscheinlichkeit, dass jede Null einem Minimum und keine Null einem Maximum entspricht, ziemlich gering. In einem Raum mit vielen Dimensionen sind Sattelpunkte ziemlich häufig, und wir wollen nicht an ihnen Halt machen.\n",
    "\n",
    "<img src=\"images/teke15.png\" width=\"800\">\n",
    "\n",
    "_Illustration: ein Sattelpunkt. Die Steigung ist 0, aber sie ist nicht in allen Richtungen ein Minimum. (Bildnachweis Wikimedia: [Von Nicoguaro - Eigenes Werk, CC BY 3.0](https://commons.wikimedia.org/w/index.php?curid=20570051))\n",
    "\n",
    "Die Lösung besteht darin, dem Optimierungsalgorithmus etwas Schwung zu verleihen, damit er an Sattelpunkten vorbeisegeln kann, ohne anzuhalten.\n",
    "\n",
    "<p style='background :#eeee88' > \n",
    "Die TensorFlow-Bibliothek bietet eine ganze Reihe von Optimierern, angefangen mit dem einfachen Gradientenabstieg <b>tf.keras.optimizers.SGD</b>, der jetzt einen optionalen Momentum-Parameter hat. Fortgeschrittenere populäre Optimierer, die einen eingebauten Impuls haben, sind <b>tf.keras.optimizers.RMSprop</b> oder <b>tf.keras.optimizers.Adam</b>.\n",
    "</p>\n",
    "\n",
    "#### Glossar\n",
    "\n",
    "__batch__ oder __mini-batch__: Das Training wird immer mit Batches von Trainingsdaten und Labels durchgeführt. Dadurch wird die Konvergenz des Algorithmus gefördert. Die \"Batch\"-Dimension ist normalerweise die erste Dimension von Datentensoren. Ein Tensor der Form [100, 192, 192, 3] enthält zum Beispiel 100 Bilder mit 192x192 Pixeln und drei Werten pro Pixel (RGB).\n",
    "\n",
    "__cross-entropy-loss__: eine spezielle Verlustfunktion, die häufig in Klassifikatoren verwendet wird.\n",
    "\n",
    "__dense layer__: eine Schicht von Neuronen, bei der jedes Neuron mit allen Neuronen der vorherigen Schicht verbunden ist.\n",
    "\n",
    "__features__: Die Eingaben eines neuronalen Netzes werden manchmal als \"Features\" (Merkmale) bezeichnet. Die Kunst, herauszufinden, welche Teile eines Datensatzes (oder Kombinationen von Teilen) in ein neuronales Netz eingespeist werden können, um gute Vorhersagen zu erhalten, wird \"Feature Engineering\" genannt.\n",
    "\n",
    "__labels__: eine andere Bezeichnung für \"Klassen\" oder richtige Antworten in einem überwachten Klassifizierungsproblem\n",
    "\n",
    "__learning rate__: Anteil des Gradienten, um den die Gewichte und Verzerrungen bei jeder Iteration der Trainingsschleife aktualisiert werden.\n",
    "\n",
    "__logits__: Die Ausgaben einer Schicht von Neuronen vor der Anwendung der Aktivierungsfunktion werden als \"Logits\" bezeichnet. Der Begriff stammt von der \"logistischen Funktion\", auch bekannt als \"Sigmoidfunktion\", die früher die beliebteste Aktivierungsfunktion war. \"Neuronenausgänge vor logistischer Funktion\" wurde zu \"Logits\" verkürzt.\n",
    "\n",
    "__loss__: Die Fehlerfunktion, die die Ausgaben des neuronalen Netzes mit den richtigen Antworten vergleicht\n",
    "\n",
    "__neuron__: berechnet die gewichtete Summe seiner Eingänge, fügt einen \"bias\" hinzu und leitet das Ergebnis durch eine Aktivierungsfunktion.\n",
    "\n",
    "__one-hot encoding__: Klasse 3 von 10 wird als Vektor mit 10 Elementen kodiert, die alle Nullen sind, außer der 3.\n",
    "\n",
    "__relu__: gleichgerichtete lineare Einheit. Eine beliebte Aktivierungsfunktion für Neuronen.\n",
    "\n",
    "__sigmoid__: eine weitere Aktivierungsfunktion, die früher sehr beliebt war und in speziellen Fällen immer noch nützlich ist.\n",
    "\n",
    "__softmax__: eine spezielle Aktivierungsfunktion, die auf einen Vektor einwirkt, die Differenz zwischen der größten Komponente und allen anderen vergrößert und außerdem den Vektor so normalisiert, dass er eine Summe von 1 hat, so dass er als ein Vektor von Wahrscheinlichkeiten interpretiert werden kann. Wird als letzter Schritt in Klassifikatoren verwendet.\n",
    "\n",
    "__tensor__: Ein \"Tensor\" ist wie eine Matrix, jedoch mit einer beliebigen Anzahl von Dimensionen. Ein 1-dimensionaler Tensor ist ein Vektor. Ein 2-dimensionaler Tensor ist eine Matrix. Und dann kann man Tensoren mit 3, 4, 5 oder mehr Dimensionen haben.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c1bee-d3eb-4ddd-9a58-d112cdd14455",
   "metadata": {},
   "source": [
    "## 5. Starten wir mit dem Code\n",
    "Jetzt beschäftigen wir uns mit dem Code.\n",
    "\n",
    "<img src=\"images/teke00.png\" width=\"20\" height=\"20\">  [keras_01_mnist.ipynb](keras_01_mnist.ipynb)\n",
    "\n",
    "#### HANDS ON:\n",
    "<p style='background :#fcf3cf'> \n",
    "Ihre Aufgabe in diesem Abschnitt ist es, den Code zu lesen und zu verstehen, damit wir ihn später verbessern können.\n",
    "</p>\n",
    "Gehen wir nun alle Zellen in diesem Notizbuch durch.\n",
    "\n",
    "__Zelle \"Parameter\"__   \n",
    "Hier werden die Stapelgröße, die Anzahl der Trainingsepochen und der Speicherort der Datendateien festgelegt.\n",
    "\n",
    "__Zelle \"Importe\"__   \n",
    "Alle notwendigen Python-Bibliotheken werden hier importiert, einschließlich TensorFlow und auch matplotlib für Visualisierungen.\n",
    "\n",
    "__Zelle \"Visualization Utilities\"__ *** Ausführen!!   \n",
    "Diese Zelle enthält uninteressanten Visualisierungscode. Sie ist standardmäßig eingeklappt, aber Sie können sie öffnen und sich den Code ansehen, wenn Sie Zeit haben, indem Sie darauf doppelklicken.\n",
    "<p style='background :#fcf3cf' > \n",
    "Sie müssen diese Zelle ausführen (SHIFT-ENTER), sonst werden die darin definierten Funktionen nicht geparst und Sie erhalten später Fehler.\n",
    "</p>\n",
    "__Zelle \"tf.data.Dataset: Dateien parsen und Trainings- und Validierungsdatensätze vorbereiten\"__   \n",
    "Diese Zelle verwendet die tf.data.Dataset API, um den MNIST-Datensatz aus den Datendateien zu laden. Es ist nicht notwendig, zu viel Zeit auf diese Zelle zu verwenden. Wenn Sie an der tf.data.Dataset API interessiert sind, finden Sie hier ein Tutorial, das sie erklärt: [TPU-speed data pipelines](https://www.tensorflow.org/guide/data_performance).  \n",
    "\n",
    "__Aktuell reichen folgende Basics:__  \n",
    "Bilder und Beschriftungen (richtige Antworten) aus dem MNIST-Datensatz werden in Datensätzen fester Länge in 4 Dateien gespeichert. Die Dateien können mit der speziellen Funktion für feste Datensätze geladen werden:\n",
    "\n",
    "> `imagedataset = tf.data.FixedLengthRecordDataset(image_filename, 28*28, header_bytes=16)`\n",
    "\n",
    "Wir haben nun einen Datensatz mit Bytes von Bildern. Diese müssen in Bilder dekodiert werden. Wir definieren eine Funktion, die dies tut. Das Bild ist nicht komprimiert, so dass die Funktion nichts zu dekodieren braucht (`decode_raw` macht im Grunde nichts). Das Bild wird dann in Fließkommawerte zwischen 0 und 1 umgewandelt. Wir könnten es hier als 2D-Bild umformen, aber eigentlich behalten wir es als flaches Array von Pixeln der Größe 28*28 bei, weil das unsere erster dense Layer erwartet.\n",
    "\n",
    ">`def read_image(tf_bytestring):`  \n",
    "`    image = tf.io.decode_raw(tf_bytestring, tf.uint8)`  \n",
    "`    image = tf.cast(image, tf.float32)/256.0`  \n",
    "`    image = tf.reshape(image, [28*28])`  \n",
    "`    return image`  \n",
    "\n",
    "Wir wenden diese Funktion mit `.map` auf den Datensatz an und erhalten einen Datensatz mit Bildern:\n",
    "\n",
    ">`imagedataset = imagedataset.map(read_image, num_parallel_calls=16)`\n",
    "\n",
    "Wir Lesen und Dekodieren unsere Labels auf die gleiche Art und Weise. Danach fügen wir per `.zip` Bilder und labels (Beschriftungen) zusammen:\n",
    "\n",
    ">`dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))`\n",
    "\n",
    "Wir haben nun einen Datensatz mit Paaren bestehend aus Image und Label. Das ist es, was unser Modell erwartet. Wir sind noch nicht ganz so weit, ihn in der Trainingsfunktion zu verwenden:\n",
    "\n",
    ">`dataset = dataset.cache()`  \n",
    "`dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)`  \n",
    "`dataset = dataset.repeat()`  \n",
    "`dataset = dataset.batch(batch_size)`  \n",
    "`dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)`  \n",
    "\n",
    "Die `tf.data.Dataset` API verfügt über alle notwendigen Funktionen zur Vorbereitung von Datensätzen:\n",
    "\n",
    "`.cache` speichert das Dataset im RAM. Dies ist ein winziger Datensatz, also wird er funktionieren. `.shuffle` mischt ihn mit einem Puffer von 5000 Elementen. Es ist wichtig, dass die Trainingsdaten gut gemischt sind. `.repeat` lässt den Datensatz in einer Schleife laufen. Wir werden mehrmals damit trainieren (mehrere Epochen). `.batch` fasst mehrere Bilder und Beschriftungen zu einem Mini-Batch zusammen. Schließlich kann `.prefetch` die CPU nutzen, um den nächsten Stapel vorzubereiten, während der aktuelle Stapel auf der GPU trainiert wird.\n",
    "\n",
    "Der Validierungsdatensatz wird auf ähnliche Weise vorbereitet. Wir sind nun bereit, ein Modell zu definieren und diesen Datensatz zum Trainieren zu verwenden.\n",
    "\n",
    "__Zelle \"Keras-Modell\"__\n",
    "\n",
    "Alle unsere Modelle werden geradlinige Sequenzen von Schichten sein, so dass wir den Stil `tf.keras.Sequential` verwenden können, um sie zu erstellen. Hier handelt es sich zunächst um eine einzelne \"dense layer\" (dichte Schicht). Sie hat 10 Neuronen, weil wir handgeschriebene Ziffern in 10 Klassen klassifizieren. Es verwendet eine Softmax-Aktivierung, weil es die letzte Schicht in einem Klassifikator ist.\n",
    "\n",
    "Ein Keras-Modell muss auch die Form seiner Eingaben kennen. `tf.keras.layers.Input` kann verwendet werden, um sie zu definieren. Hier sind die Eingabevektoren flache Vektoren von Pixelwerten der Länge 28*28.\n",
    "\n",
    "> `model = tf.keras.Sequential(`  \n",
    "`  [`  \n",
    "`    tf.keras.layers.Input(shape=(28*28,)),`  \n",
    "`    tf.keras.layers.Dense(10, activation='softmax')`  \n",
    "`  ])`  \n",
    "\n",
    ">`model.compile(optimizer='sgd',`  \n",
    "`              loss='categorical_crossentropy',`  \n",
    "`              metrics=['accuracy'])`  \n",
    "\n",
    ">`# print model layers`  \n",
    "`model.summary()`  \n",
    "\n",
    ">`# utility callback that displays training curves`  \n",
    "`plot_training = PlotTraining(sample_rate=10, zoom=1)`  \n",
    "\n",
    "Die Konfiguration des Modells erfolgt in Keras mit der Funktion `model.compile`. Hier verwenden wir den grundlegenden Optimierer `'sgd'` (Stochastic Gradient Descent). Ein Klassifizierungsmodell benötigt eine cross-entropy Verlustfunktion, in Keras `'categorical_crossentropy'` genannt. Schließlich bitten wir das Modell, die Metrik `'accuracy'`(Genauigkeit) zu berechnen, die den Prozentsatz der korrekt klassifizierten Bilder angibt.\n",
    "\n",
    "Keras bietet das sehr schöne Dienstprogramm `model.summary()`, das die Details des von Ihnen erstellten Modells ausgibt. Der Autor des Tutorial Originals hat das Dienstprogramm `PlotTraining` (definiert in der Zelle \"Visualization Utilities\") hinzugefügt, das verschiedene Trainingskurven während des Trainings anzeigt.\n",
    "\n",
    "\n",
    "__Zelle \"Trainieren und Validieren des Modells\"__\n",
    "\n",
    "Hier findet das Training statt, indem `model.fit` aufgerufen und sowohl die Trainings- als auch die Validierungsdatensätze übergeben werden. Standardmäßig führt Keras am Ende jeder Epoche eine Validierung der Ergebnisse durch.\n",
    "\n",
    ">`model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,`  \n",
    "`          validation_data=validation_dataset, validation_steps=1,`  \n",
    "`          callbacks=[plot_training])`  \n",
    "\n",
    "In Keras ist es möglich, mit Hilfe von Callbacks benutzerdefinierte Verhaltensweisen während des Trainings hinzuzufügen. Auf diese Weise wurde die dynamisch aktualisierte Trainingsdarstellung umgesetzt.\n",
    "\n",
    "__Zelle \"Vorhersagen visualisieren\"__\n",
    "Sobald das Modell trainiert ist, können wir Vorhersagen von ihm erhalten, indem wir `model.predict()` aufrufen:\n",
    "\n",
    ">`probabilities = model.predict(font_digits, steps=1)`   \n",
    "`predicted_labels = np.argmax(probabilities, axis=1)` \n",
    "\n",
    "Hier haben wir eine Reihe von gedruckten Ziffern vorbereitet, die aus lokalen Schriftarten gerendert wurden, als Test. Denken Sie daran, dass das neuronale Netz einen Vektor von 10 Wahrscheinlichkeiten aus seinem endgültigen \"softmax\" zurückgibt. Um die Bezeichnung zu erhalten, müssen wir herausfinden, welche Wahrscheinlichkeit die höchste ist. np.argmax aus der Numpy-Bibliothek erledigt das.\n",
    "\n",
    "Um zu verstehen, warum der Parameter axis=1 benötigt wird, denken Sie bitte daran, dass wir einen Stapel von 128 Bildern verarbeitet haben und das Modell daher 128 Vektoren von Wahrscheinlichkeiten liefert. Die Form des Ausgabentensors ist [128, 10]. Wir berechnen die argmax über die 10 Wahrscheinlichkeiten, die für jedes Bild zurückgegeben werden, also Achse=1 (die erste Achse ist 0).\n",
    "\n",
    "Mit diesem einfachen Modell werden bereits 90 % der Ziffern erkannt. Das ist nicht schlecht, aber wir werden es jetzt noch deutlich verbessern.\n",
    "\n",
    "\n",
    "<img src=\"images/teke16.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8d73bc-84b5-4769-8a39-858b75711c44",
   "metadata": {},
   "source": [
    "## Zusätzliche Layer (Ebenen) hinzufügen\n",
    "<img src=\"images/teke17.png\" width=\"800\">\n",
    "\n",
    "Um die Erkennungsgenauigkeit zu verbessern, werden wir weitere Schichten zum neuronalen Netzwerk hinzufügen.\n",
    "<img src=\"images/teke18.png\" width=\"800\">\n",
    "Wir behalten Softmax als Aktivierungsfunktion auf der letzten Schicht bei, da diese Funktion am besten für die Klassifizierung geeignet ist. Auf den Zwischenschichten werden wir jedoch die klassische Sigmoid Aktivierungsfunktion verwenden.\n",
    "<img src=\"images/teke19.png\" width=\"500\">\n",
    "\n",
    "#### Übung:\n",
    "<p style='background :#fcf3cf'>\n",
    "Fügen Sie vor Ihrer \"softmax\"-Schicht ein paar dichte Zwischenschichten ein, die mit \"sigmoid\" aktiviert werden. Die Anzahl der Neuronen in diesen Schichten kann zwischen 784 (Anzahl der Eingabepixel) und 10 (Anzahl der Ausgabeneuronen) liegen. Danach trainieren Sie das Modell erneut.</br></br> \n",
    "<b>Achtung</b>: Um das Modell neu zu trainieren, müssen Sie die Zelle \"Keras-Modell\" erneut ausführen, um ein neues Modell zu definieren, und anschließend die Trainingszelle. Wenn Sie nur die Trainingszelle erneut ausführen, wird das Training des vorherigen Modells fortgesetzt.\n",
    "</p>\n",
    "\n",
    "Ihr Modell könnte zum Beispiel so aussehen (vergessen Sie die Kommas nicht, `tf.keras.Sequential` nimmt eine durch Kommas getrennte Liste von Schichten):\n",
    "\n",
    ">`model = tf.keras.Sequential(`  \n",
    "`  [`  \n",
    "`      tf.keras.layers.Input(shape=(28*28,)),`  \n",
    "`      tf.keras.layers.Dense(200, activation='sigmoid'),`  \n",
    "`      tf.keras.layers.Dense(60, activation='sigmoid'),`  \n",
    "`      tf.keras.layers.Dense(10, activation='softmax')`  \n",
    "`  ])`  \n",
    "\n",
    "<img src=\"images/teke20.png\" width=\"800\">\n",
    "Auch der loss (Verlust)  scheint in die Höhe geschossen zu sein. Irgendetwas stimmt da nicht ganz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ae3006-dfac-44c8-83af-a42f4bf7b3d8",
   "metadata": {},
   "source": [
    "## 7. Besondere Vorsicht bei tiefen Netzen\n",
    "\n",
    "Sie haben soeben neuronale Netze erlebt, wie man sie in den 80er und 90er Jahren entworfen hat. Kein Wunder, dass man die Idee aufgegeben hat und der so genannte \"KI-Winter\" eingeleitet wurde. Je mehr Schichten man hinzufügt, desto mehr Schwierigkeiten haben neuronale Netze, zu konvergieren.\n",
    "\n",
    "Es hat sich herausgestellt, dass tiefe neuronale Netze mit vielen Schichten (20, 50, heute sogar 100) sehr gut funktionieren können, wenn man ein paar mathematische Tricks anwendet, um sie konvergieren zu lassen. Die Entdeckung dieser einfachen Tricks ist einer der Gründe für die Renaissance des Deep Learning in den 2010er Jahren.\n",
    "\n",
    "#### RELU-Aktivierung\n",
    "<img src=\"images/teke21.png\" width=\"800\">\n",
    "\n",
    "Die sigmoid Aktivierungsfunktion ist in tiefen Netzen eigentlich recht problematisch. Sie quetscht alle Werte zwischen 0 und 1, und wenn Sie dies wiederholt tun, können die Neuronenausgaben und ihre Gradienten vollständig verschwinden. Die Sigmoid Funktion wurde aus historischen Gründen erwähnt, aber moderne Netze verwenden die RELU (Rectified Linear Unit), die wie folgt aussieht:\n",
    "\n",
    "<img src=\"images/teke22.png\" width=\"500\">\n",
    "\n",
    "#### Übung:\n",
    "<p style='background :#fcf3cf'>\n",
    "Ersetzen Sie alle <b>activation='sigmoid'</b> durch <b>activation='relu'</b> in den einzelnen Schichten. Trainieren Sie das neuronale Netzwerk erneut.    \n",
    "</p>\n",
    "\n",
    "\n",
    "#### Warum ist die Verwendung der Sigmoid-Aktivierungsfunktion problematisch?\n",
    "Sehen Sie sich an, wie es sich an den Seiten verhält: Es wird flach.\n",
    "<img src=\"images/teke23.png\" width=\"500\">   \n",
    "Und das bedeutet, dass seine Ableitung dort nahe Null ist. Erinnern Sie sich daran, wie das Training voranschreitet, indem Sie dem Gradienten folgen, der ein Vektor von Ableitungen ist. Bei einer sigmoidalen Aktivierung, vor allem wenn es viele Schichten gibt, kann der Gradient sehr klein werden und das Training wird immer langsamer.\n",
    "\n",
    "Die  Relu-Aktivierungsfunktion hingegen hat eine Ableitung von 1, zumindest auf seiner rechten Seite. Bei der RELU-Aktivierungsfunktion können die Gradienten einiger Neuronen zwar Null sein, aber es wird immer andere geben, die einen eindeutigen Nicht-Null-Gradienten aufweisen, und das Training kann in einem guten Tempo fortgesetzt werden.\n",
    "\n",
    "#### Ein besserer Optimierer\n",
    "In sehr hochdimensionalen Räumen wie hier - wir haben in der Größenordnung von 10.000 weights (Gewichten) und biases (Verzerrungen) - treten häufig \"Sattelpunkte\" auf. Das sind Punkte, die keine lokalen Minima sind, aber an denen der Gradient trotzdem Null ist und der Gradientenabstiegsoptimierer dort stecken bleibt. TensorFlow hat eine ganze Reihe von verfügbaren Optimierern, darunter einige, die mit einer gewissen Trägheit arbeiten und sicher an Sattelpunkten vorbeisegeln.\n",
    "\n",
    "#### Übung:\n",
    "<p style='background :#fcf3cf'>\n",
    "Ersetzen Sie den Optimierer <b>'sgd'</b> durch einen besseren, zum Beispiel <b>'adam'</b>. Trainieren Sie das Netz erneut.   \n",
    "</p>\n",
    "\n",
    "#### Zufällige Initialisierungen\n",
    "\n",
    "Die Kunst, Gewichte vor dem Training zu initialisieren, ist ein eigenes Forschungsgebiet mit zahlreichen Veröffentlichungen zu diesem Thema. Sie können einen Blick auf alle in Keras verfügbaren Initialisierungen werfen, und zwar hier. Glücklicherweise tut Keras standardmäßig das Richtige und verwendet den Initialisierer \"glorot_uniform\", der in fast allen Fällen der beste ist.\n",
    "\n",
    "Sie müssen nichts weiter tun, da Keras bereits das Richtige tut.\n",
    "\n",
    "#### NaN?\n",
    "Die Cross-Entropie-Formel beinhaltet einen Logarithmus und log(0) ist Not a Number (NaN, ein numerischer Absturz, wenn Sie so wollen). Kann die Eingabe für die Cross-Entropie 0 sein? Die Eingabe kommt von Softmax, das im Wesentlichen ein Exponentialwert ist, und ein Exponentialwert ist niemals Null. Wir sind also sicher!\n",
    "Wirklich sicher? In der schönen Welt der Mathematik wären wir sicher, aber in der Computerwelt ist exp(-150), dargestellt im float32-Format, so gut wie NULL, und die Kreuzentropie stürzt ab.\n",
    "Glücklicherweise müssen Sie auch hier nichts tun, denn Keras kümmert sich darum und berechnet softmax gefolgt von der Cross-Entropie auf besonders sorgfältige Weise, um die numerische Stabilität zu gewährleisten und die gefürchteten NaNs zu vermeiden.\n",
    "\n",
    "#### Erfolgreich?\n",
    "<img src=\"images/teke23.png\" width=\"500\">\n",
    "\n",
    "Sie sollten jetzt eine Genauigkeit von 97 % erreichen. Unser Ziel ist es, deutlich über 99 % zu kommen, also lassen Sie uns weitermachen.\n",
    "\n",
    "Wenn Sie nicht weiterkommen, hier ist die Lösung für diesen Punkt:\n",
    "\n",
    "<img src=\"images/teke00.png\" width=\"20\" height=\"20\">  [keras_02_mnist_dense.ipynb](keras_02_mnist_dense.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d9643a-f203-444c-aba2-a92eb921aa33",
   "metadata": {},
   "source": [
    "## 8. Learning rate decay (Verfall der Lernrate)\n",
    "\n",
    "Vielleicht können wir versuchen, schneller zu trainieren? Die Standard-Lernrate im Adam-Optimierer ist 0,001. Versuchen wir, sie zu erhöhen.\n",
    "\n",
    "#### Übung\n",
    "<p style='background :#fcf3cf'>\n",
    "Erhöhen Sie die Lernrate von ihrem Standardwert 0.001 auf 0.01. Dazu müssen Sie den vordefinierten Optimierer <b>'adam'</b> durch eine tatsächliche Instanz eines Adam-Optimierers ersetzen, damit Sie Zugriff auf dessen Konfigurationsparameter haben:\n",
    "</p>\n",
    "\n",
    ">`optimizer=tf.keras.optimizers.Adam(lr=0.01)` \n",
    "\n",
    "<p style='background :#fcf3cf'>\n",
    "Erhöhen Sie bitte auch den Zoomfaktor in PlotTraining auf 5. Dies zoomt um 0 auf Verluste und um 1 auf Genauigkeiten, damit Sie besser sehen können, was vor sich geht: </p>  \n",
    "\n",
    ">`PlotTraining(sample_rate=10, zoom=5)`  \n",
    "\n",
    "Schneller zu gehen scheint nicht viel zu helfen, und was ist das für ein Rauschen?\n",
    "\n",
    "<img src=\"images/teke25.png\" width=\"800\">\n",
    "Die Trainingskurven sind wirklich verrauscht, und sehen Sie sich die beiden Validierungskurven an: Sie springen auf und ab. Das bedeutet, dass wir zu schnell vorgehen. Wir könnten zu unserer vorherigen Geschwindigkeit zurückkehren, aber es gibt einen besseren Weg.\n",
    "<img src=\"images/teke26.png\" width=\"800\">\n",
    "\n",
    "Eine gute Lösung ist es, schnell zu beginnen und die Lernrate exponentiell abfallen zu lassen. In Keras können Sie dies mit dem Callback `tf.keras.callbacks.LearningRateScheduler` erreichen.\n",
    "\n",
    "#### Übung:\n",
    "<p style='background :#fcf3cf'>\n",
    "Implementieren Sie einen Lernratenplan, der die Lernrate exponentiell abfallen lässt. Nachfolgend finden Sie nützliche Codeschnipsel.\n",
    "</p>\n",
    "Nützlicher Code zum Kopieren und Einfügen:\n",
    "\n",
    ">`# lr decay function`   \n",
    "`def lr_decay(epoch):`   \n",
    "`  return 0.01 * math.pow(0.6, epoch)`  \n",
    "\n",
    ">`# lr schedule callback`  \n",
    "`lr_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=True)`  \n",
    "\n",
    ">`# important to see what you are doing`   \n",
    "`plot_learning_rate(lr_decay, EPOCHS)`  \n",
    "\n",
    "Vergessen Sie nicht, den von Ihnen erstellten `lr_decay_callback` zu verwenden. Fügen Sie ihn der Liste der Rückrufe in `model.fit` hinzu:\n",
    "\n",
    ">`model.fit(...,  callbacks=[plot_training, lr_decay_callback])` \n",
    "\n",
    "Die Auswirkungen dieser kleinen Änderung sind spektakulär. Sie sehen, dass das meiste Rauschen verschwunden ist und die Testgenauigkeit nun dauerhaft über 98 % liegt.\n",
    "\n",
    "<img src=\"images/teke27.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa211d-dc3e-4c1f-9f74-60a2e7633b37",
   "metadata": {},
   "source": [
    "## 9. Dropout, overfitting\n",
    "Das Modell scheint jetzt gut zu konvergieren. Lassen Sie uns versuchen, noch tiefer zu gehen.\n",
    "\n",
    "#### Übung\n",
    "<p style='background :#fcf3cf'>\n",
    "Wenn Sie es noch nicht getan haben, erhöhen Sie die Tiefe des Modells auf mindestens 4 dichte Schichten und trainieren Sie erneut. Sie können die folgende Anzahl von Neuronen in den Schichten verwenden: 200, 100, 60, 10.</p>\n",
    "<p style='background :#fcf3cf'>\n",
    "Erhöhen Sie bitte auch den Zoomfaktor in PlotTraining auf 10. Dies zoomt bei den Verlusten um 0 und bei den Genauigkeiten um 1, damit Sie besser sehen können, was vor sich geht: <b>PlotTraining(sample_rate=10, zoom=10)</b>\n",
    "</p>\n",
    "\n",
    "__Hilft das?__   \n",
    "<img src=\"images/teke28.png\" width=\"800\">   \n",
    "Nicht wirklich, die Genauigkeit liegt immer noch bei 98 %, und sehen Sie sich den Validierungsverlust an. Er steigt an! Der Lernalgorithmus arbeitet nur mit Trainingsdaten und optimiert den Trainingsverlust entsprechend. Da er nie Validierungsdaten sieht, ist es nicht verwunderlich, dass seine Arbeit nach einer Weile keine Auswirkungen mehr auf den Validierungsverlust hat (val_loss), der nicht mehr sinkt und manchmal sogar wieder ansteigt.\n",
    "\n",
    "Dies wirkt sich nicht unmittelbar auf die realen Erkennungsfähigkeiten Ihres Modells aus, aber es verhindert, dass Sie viele Iterationen durchführen, und ist im Allgemeinen ein Zeichen dafür, dass das Training keinen positiven Effekt mehr hat.\n",
    "\n",
    "Diese Unterbrechung wird in der Regel als \"Überanpassung\" bezeichnet, und wenn Sie dies feststellen, können Sie versuchen, eine Regularisierungstechnik namens \"Dropout\" anzuwenden. Bei der Dropout-Technik werden bei jeder Trainingsiteration zufällige Neuronen abgeschossen.\n",
    "\n",
    "<img src=\"images/teke29.png\" width=\"800\">\n",
    "\n",
    "<p style='background :#eeee88' >  \n",
    "Dropout ist eine der ältesten Regularisierungstechniken beim Deep Learning. Bei jeder Trainingsiteration werden zufällige Neuronen mit einer Wahrscheinlichkeit p (in der Regel 25 % bis 50 %) aus dem Netzwerk entfernt. In der Praxis werden die Neuronenausgänge auf 0 gesetzt. Das Nettoergebnis ist, dass diese Neuronen dieses Mal nicht an der Verlustberechnung teilnehmen und keine Gewichtsaktualisierungen erhalten. Bei jedem Trainingsdurchgang werden andere Neuronen fallen gelassen.</p>\n",
    "<img src=\"images/teke30.png\" width=\"800\">\n",
    "<p style='background :#eeee88' > \n",
    "Wenn Sie die Leistung Ihres Netzes testen, müssen Sie natürlich alle Neuronen zurücksetzen (Dropout-Rate=0). Keras macht das automatisch, Sie müssen also nur eine <b>tf.keras.layers.Dropout</b>-Schicht hinzufügen. Sie wird automatisch das richtige Verhalten beim Training und bei der Auswertung haben.\n",
    "Warum funktioniert das? Die Theorie besagt, dass neuronale Netze so viel Freiheit zwischen ihren zahlreichen Schichten haben, dass es durchaus möglich ist, dass eine Schicht ein schlechtes Verhalten entwickelt und die nächste Schicht dies kompensiert. Dies ist keine ideale Nutzung von Neuronen. Beim Dropout ist die Wahrscheinlichkeit groß, dass das Neuron, das das Problem \"behebt\", in einer bestimmten Trainingsrunde nicht vorhanden ist. Das schlechte Verhalten der fehlerhaften Schicht wird offensichtlich und die Gewichte entwickeln sich in Richtung eines besseren Verhaltens.\n",
    "</p>\n",
    "\n",
    "#### Übung\n",
    "<p style='background :#fcf3cf'>\n",
    "Sie können Dropouts nach jeder dichten Zwischenschicht im Netz hinzufügen. Fügen Sie kein Dropout nach der Softmax-Schicht hinzu. Sie würden damit Ihre vorhergesagten Wahrscheinlichkeiten verwerfen. Sie können eine Dropout-Rate von 25 % hinzufügen mit: <b>tf.keras.layers.Dropout(0.25)</b>\n",
    "</p>\n",
    "\n",
    "__Funktioniert das?__\n",
    "<img src=\"images/teke31.png\" width=\"800\">\n",
    "\n",
    "Das Rauschen taucht wieder auf (was angesichts der Funktionsweise von Dropout nicht überrascht). Die Validierungsverluste scheinen nicht mehr anzusteigen, aber sie sind insgesamt höher als ohne Dropout. Und die Validierungsgenauigkeit ist etwas gesunken. Dies ist ein ziemlich enttäuschendes Ergebnis.\n",
    "\n",
    "Es sieht so aus, als ob \"Dropout\" nicht die richtige Lösung war, oder vielleicht ist \"Overfitting\" ein komplexeres Konzept und einige seiner Ursachen lassen sich nicht mit \"Dropout\" beheben?\n",
    "\n",
    "Was ist \"Überanpassung\"? Überanpassung liegt vor, wenn ein neuronales Netz \"schlecht\" lernt, d. h. auf eine Art und Weise, die bei den Trainingsbeispielen funktioniert, aber nicht so gut bei realen Daten. Es gibt Regularisierungstechniken wie Dropout, die ein besseres Lernen erzwingen können, aber Overfitting hat auch tiefere Wurzeln.\n",
    "\n",
    "<img src=\"images/teke32.png\" width=\"800\">\n",
    "Eine grundlegende Überanpassung liegt vor, wenn ein neuronales Netz zu viele Freiheitsgrade für das vorliegende Problem hat. Stellen Sie sich vor, wir hätten so viele Neuronen, dass das Netz alle unsere Trainingsbilder in ihnen speichern und dann durch Mustervergleich erkennen könnte. Bei realen Daten würde es völlig versagen. Ein neuronales Netz muss in gewisser Weise eingeschränkt werden, damit es gezwungen ist, das, was es beim Training lernt, zu verallgemeinern.\n",
    "\n",
    "Wenn Sie nur sehr wenige Trainingsdaten haben, kann selbst ein kleines Netz diese auswendig lernen, und es kommt zu einer \"Überanpassung\". Im Allgemeinen braucht man immer eine große Menge an Daten, um neuronale Netze zu trainieren.\n",
    "\n",
    "Und wenn Sie alles nach Vorschrift gemacht haben, mit verschiedenen Netzgrößen experimentiert haben, um sicherzustellen, dass die Freiheitsgrade begrenzt sind, Dropout angewendet haben und mit vielen Daten trainiert haben, kann es sein, dass Sie immer noch auf einem Leistungsniveau feststecken, das sich nicht verbessern lässt. Das bedeutet, dass Ihr neuronales Netz in seiner jetzigen Form nicht in der Lage ist, mehr Informationen aus Ihren Daten zu extrahieren, wie in unserem Fall hier.\n",
    "\n",
    "Erinnern Sie sich daran, dass wir unsere Bilder zu einem einzigen Vektor geglättet haben? Das war eine wirklich schlechte Idee. Handgeschriebene Ziffern bestehen aus Formen, und wir haben die Forminformationen verworfen, als wir die Pixel platt gemacht haben. Es gibt jedoch eine Art von neuronalen Netzen, die sich die Forminformationen zunutze machen können: Faltungsnetze. Wir wollen sie ausprobieren.\n",
    "\n",
    "Wenn Sie nicht weiterkommen, hier ist die Lösung für diesen Punkt:   \n",
    "<img src=\"images/teke00.png\" width=\"20\" height=\"20\">  [keras_03_mnist_dense_lrdecay_dropout.ipynb](keras_03_mnist_dense_lrdecay_dropout.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2b741-72ea-4088-b40b-010bae23d614",
   "metadata": {},
   "source": [
    "## 10. [INFO] convolutional networks \n",
    "#### Auf den Punkt gebracht\n",
    "Wenn Ihnen alle fettgedruckten Begriffe im nächsten Abschnitt bereits bekannt sind, können Sie mit der nächsten Übung fortfahren. Wenn Sie gerade erst mit Faltung bei neuronalen Netzen anfangen, lesen Sie bitte weiter.\n",
    "\n",
    "<img src=\"images/teke33.gif\" width=\"800\">\n",
    "\n",
    "_Abbildung: Filtern eines Bildes mit zwei aufeinanderfolgenden Filtern, die jeweils aus 4x4x3=48 lernbaren Gewichten bestehen._\n",
    "\n",
    "<p style='background :#eeee88'>  \n",
    "Convolutional neural networks (Neuronale Faltungsnetze) wenden eine Reihe von lernfähigen Filtern auf das Eingangsbild an. Eine Faltungsschicht wird durch die Größe des Filters (oder Kernels), die Anzahl der angewandten Filter und die Schrittweite definiert. Die Eingabe und die Ausgabe einer Faltungsschicht haben jeweils drei Dimensionen (Breite, Höhe, Anzahl der Kanäle), beginnend mit dem Eingabebild (Breite, Höhe, RGB-Kanäle). Beim Stapeln von Faltungsschichten können die Breite und Höhe der Ausgabe durch einen Stride >1 oder durch eine Max-Pooling-Operation angepasst werden. Die Tiefe der Ausgabe (Anzahl der Kanäle) wird durch die Verwendung von mehr oder weniger Filtern eingestellt.    \n",
    "<p>\n",
    "\n",
    "So sieht ein einfaches \"convolutional neural network\" in Keras aus:   \n",
    "    \n",
    ">`model = tf.keras.Sequential([`  \n",
    "`    tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),`  \n",
    "`    tf.keras.layers.Conv2D(kernel_size=3, filters=12, activation='relu'),`  \n",
    "`    tf.keras.layers.Conv2D(kernel_size=6, filters=24, strides=2, activation='relu'),`  \n",
    "`    tf.keras.layers.Conv2D(kernel_size=6, filters=32, strides=2, activation='relu'),`  \n",
    "`    tf.keras.layers.Flatten(),`  \n",
    "`    tf.keras.layers.Dense(10, activation='softmax')`  \n",
    "`])`  \n",
    "    \n",
    "In einer Schicht eines \"convolutional network\" führt ein \"Neuron\" eine gewichtete Summe der Pixel direkt über ihm durch, und zwar nur in einem kleinen Bereich des Bildes. Es fügt einen \"bias\" hinzu und leitet die Summe durch eine Aktivierungsfunktion, so wie es ein Neuron in einer normalen dense Layer (dichten Schicht) tun würde. Dieser Vorgang wird dann für das gesamte Bild mit denselben Gewichten wiederholt. Sie erinnern sich, dass in dense Layern jedes Neuron seine eigenen Gewichte hatte. Hier gleitet ein einziger \"Fleck\" von Gewichten in beide Richtungen über das Bild (eine \"Faltung\"). Die Ausgabe hat so viele Werte, wie es Pixel im Bild gibt (an den Rändern ist allerdings eine gewisse Auffüllung erforderlich). Es handelt sich um einen Filterungsvorgang. In der obigen Abbildung wird ein Filter mit 4x4x3=48 Gewichten verwendet.\n",
    "\n",
    "48 Gewichte sind jedoch nicht genug. Um weitere Freiheitsgrade hinzuzufügen, wiederholen wir den gleichen Vorgang mit einer neuen Menge von Gewichten. So entsteht ein neuer Satz von Filterausgängen. In Analogie zu den R-, G- und B-Kanälen des Eingangsbildes nennen wir sie einen \"Kanal\" von Ausgängen.    \n",
    "    \n",
    "<img src=\"images/teke35.png\" width=\"800\">   \n",
    "Die beiden (oder mehr) Sätze von Gewichten können durch Hinzufügen einer neuen Dimension zu einem Tensor zusammengefasst werden. So erhalten wir die allgemeine Form des Gewichtungstensors für eine Faltungsschicht. Da die Anzahl der Eingangs- und Ausgangskanäle Parameter sind, können wir mit dem Stapeln und Verketten von Faltungsschichten beginnen. \n",
    "    \n",
    "<img src=\"images/teke36.png\" width=\"800\">  \n",
    "\n",
    "_Zur Veranschaulichung: Ein neuronales Faltungsnetzwerk wandelt \"Datenwürfel\" in andere \"Datenwürfel\" um._  \n",
    "    \n",
    "#### Strided Convolutions, Max Pooling\n",
    "\n",
    "Indem man die Faltungen mit einem Stride von 2 oder 3 durchführt, kann man den resultierenden Datenwürfel auch in seinen horizontalen Dimensionen schrumpfen. Hierfür gibt es zwei gängige Methoden:\n",
    "\n",
    "* Strided convolution: ein gleitender Filter wie oben, aber mit einem Stride >1\n",
    "* Max pooling: ein gleitendes Fenster, das die MAX-Operation anwendet (typischerweise auf 2x2 Feldern, alle 2 Pixel wiederholt)\n",
    "<img src=\"images/teke37.gif\" width=\"800\">  \n",
    "    \n",
    "_Zur Veranschaulichung: Das Verschieben des Berechnungsfensters um 3 Pixel führt zu weniger Ausgabewerten. Gestufte Faltungen oder Max-Pooling (Max auf einem 2x2-Fenster, das um eine Schrittweite von 2 verschoben wird) sind eine Möglichkeit, den Datenwürfel in den horizontalen Dimensionen zu verkleinern._    \n",
    "    \n",
    "<p style='background :#eeee88'><b>\"Max-pooling\"</b> kann uns helfen, intuitiv zu verstehen, wie Faltungsnetzwerke funktionieren: Wenn man davon ausgeht, dass sich die Gewichte während des Trainings zu Filtern entwickeln, die grundlegende Formen erkennen (horizontale und vertikale Linien, Kurven, ...), dann besteht eine Möglichkeit, nützliche Informationen zu reduzieren, darin, die Ausgänge, bei denen eine Form mit der maximalen Intensität erkannt wurde, in den Schichten zu behalten. In der Praxis werden in einer Max-Pool-Schicht die Ausgänge der Neuronen in Gruppen von 2x2 verarbeitet, und nur der Maximalwert wird beibehalten.</p>\n",
    "\n",
    "## Die letzte Schicht\n",
    "Nach der letzten convolutional layer liegen die Daten in Form eines \"Würfels\" vor. Es gibt zwei Möglichkeiten, ihn durch die letzte dense layer zu leiten. \n",
    "\n",
    "Die erste Möglichkeit besteht darin, den Datenwürfel in einen Vektor umzuwandeln und ihn dann in die Softmax-Schicht einzuspeisen. Manchmal kann man sogar eine dichte Schicht vor der Softmax-Schicht einfügen. Dies ist in der Regel teuer in Bezug auf die Anzahl der Gewichte. Eine dichte Schicht am Ende eines Faltungsnetzes kann mehr als die Hälfte der Gewichte des gesamten neuronalen Netzes enthalten.\n",
    "\n",
    "Anstatt eine teure dichte Schicht zu verwenden, können wir den eingehenden Datenwürfel auch in so viele Teile aufteilen, wie wir Klassen haben, deren Werte mitteln und diese durch eine Softmax-Aktivierungsfunktion leiten. Diese Art des Aufbaus des Klassifikationskopfes kostet 0 Gewichte. In Keras gibt es dafür eine Schicht: `tf.keras.layers.GlobalAveragePooling2D().`\n",
    "\n",
    "<img src=\"images/teke38.png\" width=\"800\">  \n",
    "\n",
    "<p style='background :#eeee88'>\"Convolutional neural networks\" erkennen den Ort von Dingen. Wenn ein Filter stark auf ein bestimmtes Merkmal reagiert, tut er dies an einem bestimmten Ort (x, y). Je nach Zielsetzung kann ein neuronales Netz so trainiert werden, dass es diese Ortsdaten entweder verwendet oder verwirft. Bei der Verwendung von Global Average Pooling werden ausdrücklich alle Standortdaten verworfen. Das mag für einen Blumen-Klassifikator in Ordnung sein, aber für andere Aufgaben, wie z. B. das Zählen von Blumen in einem Bild, funktioniert es möglicherweise nicht gut. Seien Sie vorsichtig.</p>\n",
    "\n",
    "Springen Sie zum nächsten Abschnitt, um ein Faltungsnetzwerk für das vorliegende Problem zu erstellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5d897-8dc7-4eea-a74a-7e7a46379a2f",
   "metadata": {},
   "source": [
    "## 11. Ein convolutional network (Faltungsnetzwerk)\n",
    "\n",
    "Lassen Sie uns ein convolutional network für die Erkennung handgeschriebener Ziffern aufbauen. Wir verwenden drei Faltungsschichten oben, unsere traditionelle Softmax-Ausleseschicht unten und verbinden diese mit einer dense Layer (voll verknüpften Schicht):\n",
    "\n",
    "<img src=\"images/teke39.png\" width=\"800\"> \n",
    "\n",
    "Beachten Sie, dass die zweite und dritte Faltungsschicht einen Stride von zwei haben, was erklärt, warum sie die Anzahl der Ausgabewerte von 28x28 auf 14x14 und dann 7x7 reduzieren.\n",
    "\n",
    "__Lassen Sie uns den Keras-Code schreiben.__\n",
    "\n",
    "Besondere Aufmerksamkeit ist vor der ersten Faltungsschicht erforderlich. Sie erwartet nämlich einen 3D-Datenwürfel, aber unser Datensatz wurde bisher für dichte Schichten eingerichtet, und alle Pixel der Bilder sind zu einem Vektor abgeflacht. Wir müssen sie wieder in 28x28x1-Bilder (1 Kanal für Graustufenbilder) umformen:\n",
    "\n",
    ">`tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1))`  \n",
    "\n",
    "Sie können diese Zeile anstelle der bisherigen `tf.keras.layers.Input`-Schicht verwenden.\n",
    "\n",
    "In Keras lautet die Syntax für eine 'relu'-aktivierte Faltungsschicht:\n",
    "\n",
    "<img src=\"images/teke40.png\" width=\"500\">\n",
    "\n",
    ">`tf.keras.layers.Conv2D(kernel_size=3, filters=12, padding='same', activation='relu')` \n",
    "\n",
    "\n",
    "\n",
    "__Der Padding-Parameter in Faltungsschichten kann zwei Werte haben:__  \n",
    "* `\"same\"`: Auffüllen mit Nullen, so dass die Ausgabe die gleiche Breite/Höhe wie die Eingabe hat\n",
    "* `\"valid\"`: kein Padding, nur echte Pixel verwenden\n",
    "\n",
    "Wir verwenden hier Padding, also setzen Sie Padding bitte auf `\"same\"`.\n",
    "\n",
    "Für eine gestufte Faltung würde man schreiben:\n",
    "\n",
    ">`tf.keras.layers.Conv2D(kernel_size=6, filters=24, padding='same', activation='relu', strides=2)`  \n",
    "\n",
    "Einen Datenwürfel in einen Vektor umwandeln, damit er von einer dense Layer (dichten Schicht) verwendet werden kann:\n",
    "\n",
    ">`tf.keras.layers.Flatten()`  \n",
    "\n",
    "Und für die dense Layer hat sich die Syntax nicht geändert:\n",
    "\n",
    ">`tf.keras.layers.Dense(200, activation='relu')`  \n",
    "\n",
    "#### Übung\n",
    "<p style='background :#fcf3cf'>\n",
    "Ändern Sie Ihr Modell, um es in ein Faltungsmodell umzuwandeln. Sie können die Werte aus der obigen Zeichnung verwenden, um es zu dimensionieren. Sie können die Lernrate so belassen, wie sie war, aber bitte <b>entfernen Sie die Dropouts</b> an dieser Stelle.<br>  \n",
    "Erhöhen Sie bitte auch den Zoomfaktor in PlotTraining auf 16. Dadurch wird bei den Verlusten auf 0 und bei den Genauigkeiten auf 1 gezoomt, damit Sie besser sehen können, was vor sich geht: <b>PlotTraining(sample_rate=10, zoom=16)</b>\n",
    "</p>\n",
    "\n",
    "Hat Ihr Modell die 99%ige Genauigkeitsgrenze überschritten? Ziemlich knapp... aber sehen Sie sich die Verlustkurve der Validierung an. Kommt Ihnen das bekannt vor?\n",
    "\n",
    "<img src=\"images/teke41.png\" width=\"800\">\n",
    "\n",
    "Schauen Sie sich auch die Vorhersagen an. Zum ersten Mal sollten Sie sehen, dass die meisten der 10.000 Testziffern nun richtig erkannt werden. Es verbleiben nur noch etwa 4½ Reihen von Fehlerkennungen (etwa 110 Ziffern von 10.000)\n",
    "\n",
    "<img src=\"images/teke42.png\" width=\"800\">\n",
    "\n",
    "Wenn Sie nicht weiterkommen, hier ist die Lösung: \n",
    "<img src=\"images/teke00.png\" width=\"20\" height=\"20\">  [keras_04_mnist_convolutional.ipynb](keras_04_mnist_convolutional.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb7a07-734b-4576-8eb0-54fdffe19e21",
   "metadata": {},
   "source": [
    "## 12. Nochmal Dropout\n",
    "Das bisherige Training zeigt deutliche Anzeichen einer Überanpassung (und erreicht immer noch keine 99 % Genauigkeit). Sollten wir es noch einmal mit Dropout versuchen?\n",
    "\n",
    "#### Übung\n",
    "<p style='background :#fcf3cf'>\n",
    "    Fügen Sie zwischen die beiden <b>dense Layer</b> Ihres Netzes eine <b>dropout Layer</b> ein. Verwenden Sie eine Dropout-Rate von 40% (=0,4):<br><br>\n",
    "    <b>tf.keras.layers.Dropout(0.4)</b><br>\n",
    "<br>\n",
    "Die Anwendung von Dropout auf <b>convolutional Layer</b> ist möglich, funktioniert aber etwas anders und ist in der Regel nicht so effektiv, da es in den Faltungsschichten viel weniger Gewichte gibt und somit weniger Chancen für eine schlechte Co-Adaptation. Wir werden dies nicht untersuchen.</p>\n",
    "\n",
    "__Wie ist es dieses Mal gelaufen?__\n",
    "\n",
    "<img src=\"images/teke43.png\" width=\"800\">\n",
    "\n",
    "Es sieht so aus, als ob das Dropout dieses Mal funktioniert hat. Der Validierungsverlust schleicht sich nicht mehr ein, und die endgültige Genauigkeit sollte weit über 99 % liegen. Herzlichen Glückwunsch!\n",
    "\n",
    "Als wir das erste Mal versuchten, Dropout anzuwenden, dachten wir, wir hätten ein Problem mit der Überanpassung, aber in Wirklichkeit lag das Problem in der Architektur des neuronalen Netzes. Ohne Faltungsschichten konnten wir nicht weiterkommen, und daran konnte auch Dropout nichts ändern.\n",
    "\n",
    "Dieses Mal sieht es so aus, als ob die Überanpassung die Ursache des Problems war und das Dropout tatsächlich geholfen hat. Denken Sie daran, dass es viele Ursachen für eine Abweichung zwischen der Trainings- und der Validierungsverlustkurve geben kann, wobei der Validierungsverlust schleichend ansteigt. Überanpassung (zu viele Freiheitsgrade, die vom Netz schlecht genutzt werden) ist nur einer davon. Wenn Ihr Datensatz zu klein ist oder die Architektur Ihres neuronalen Netzes nicht angemessen ist, können Sie ein ähnliches Verhalten auf den Verlustkurven beobachten, aber Dropout hilft nicht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97112068-ac98-4bdb-8dbd-6554f01ca8cd",
   "metadata": {},
   "source": [
    "## Batch normalization\n",
    "\n",
    "<img src=\"images/teke44.png\" width=\"800\">\n",
    "Zum Schluss wollen wir versuchen, die batch normalization (Stapelnormalisierung) hinzuzufügen.\n",
    "\n",
    "#### Was ist Batch normalization?\n",
    "\n",
    "Kurz gesagt, versucht die Batch-Normalisierung, das Problem zu lösen, wie die Neuronenausgaben relativ zur Aktivierungsfunktion des Neurons verteilt sind. In einem Mini-Batch von Trainingsdaten könnte die Ausgabe eines Neurons vor der Aktivierung die folgenden Verteilungen aufweisen:\n",
    "\n",
    "<img src=\"images/teke45.png\" width=\"500\">\n",
    "\n",
    "_Zu weit links, nach sigmoidaler Aktivierung, gibt dieses Neuron fast immer 0 aus._  \n",
    "\n",
    "<img src=\"images/teke46.png\" width=\"500\">\n",
    "\n",
    "_Zu eng, dieses Neuron gibt nie eine klare 0 oder 1 aus._ \n",
    "\n",
    "<img src=\"images/teke47.png\" width=\"500\">\n",
    "\n",
    "_Das ist gar nicht so schlecht. Das Neuron wird eine ganze Reihe von Verhaltensweisen in dieser Mini-Batch haben._\n",
    "\n",
    "Um dies zu beheben, normalisiert die <b>batch normalization</b> die Neuronenausgänge über einen Trainings Batch (Stapel) von Daten, d.h. sie subtrahiert den Durchschnitt und teilt ihn durch die Standardabweichung. Genau das wäre jedoch zu brutal. Bei einer perfekt zentrierten und normal breiten Verteilung würden sich alle Neuronen überall gleich verhalten. Der Trick besteht darin, zwei zusätzliche lernbare Parameter pro Neuron einzuführen, 𝛼 und 𝛽, und diese zu berechnen:\n",
    "\n",
    "𝛼 . normalized_out + 𝛽\n",
    "\n",
    "Und dann die Aktivierungsfunktion (sigmoid, relu, ...) anwenden. Auf diese Weise entscheidet das Netz durch maschinelles Lernen, wie viel Zentrierung und Neuskalierung auf jedes Neuron angewendet werden soll. Es bleibt dem Leser überlassen, zu überprüfen, ob es Werte für 𝛼 und 𝛽 gibt, mit denen die Normalisierung vollständig entfernt werden kann, wenn dies der richtige Weg ist.\n",
    "\n",
    "In der Praxis werden 𝛼 und 𝛽 nicht immer beide benötigt. In Keras heißen sie \"scale\" und \"center\" und man kann zum Beispiel das eine oder das andere selektiv verwenden:\n",
    "\n",
    "__`tf.keras.layers.BatchNormalization(scale=False, center=True)`__\n",
    "\n",
    "Das Problem bei der Batch-Normierung ist, dass Sie zum Zeitpunkt der Vorhersage keine Trainingschargen haben, über die Sie die Statistiken Ihrer Neuronenausgaben berechnen könnten. Aber Sie brauchen diese Werte trotzdem. Dieser Teil ist ein wenig kompliziert. Während des Trainings werden der Durchschnitt und die Standardabweichung einer \"typischen\" Neuronenausgabe über eine \"ausreichende\" Anzahl von Stapeln berechnet, wobei in der Praxis ein laufender exponentieller Durchschnitt verwendet wird. Diese Statistiken werden dann zur Inferenzzeit verwendet.\n",
    "\n",
    "__Die gute Nachricht ist, dass Sie in Keras eine `tf.keras.layers.BatchNormalization`-Schicht verwenden können, und all diese Berechnungen werden automatisch durchgeführt.__\n",
    "\n",
    "Das ist die Theorie, in der Praxis müssen Sie nur ein paar Regeln beachten:\n",
    "\n",
    "#### Batch normalization \"nach Vorschrift\":\n",
    "1. Die Stapelnormierung wird zwischen der Ausgabe einer Schicht und ihrer Aktivierungsfunktion eingesetzt.\n",
    "2. Wenn Sie center=True in der Stapelnorm verwenden, brauchen Sie keine Vorspannung in Ihrer Schicht. Der Stapelnorm-Offset spielt die Rolle eines Bias.\n",
    "3. Wenn Sie eine Aktivierungsfunktion verwenden, die skaleninvariant ist (d. h. die Form nicht ändert, wenn Sie darauf zoomen), können Sie scale=False einstellen. Relu ist skaleninvariant. Sigmoid ist es nicht.\n",
    "\n",
    "Das ist die Theorie, aber der einzige Weg, um herauszufinden, ob es schlecht ist, diese Regeln zu brechen, ist, es zu versuchen.\n",
    "\n",
    "Halten wir uns vorerst an die Regeln und fügen jeder Schicht des neuronalen Netzes mit Ausnahme der letzten Schicht eine batch norm Layer hinzu. Fügen Sie diese nicht zur letzten \"Softmax\"-Schicht hinzu. Sie wäre dort nicht nützlich.\n",
    "\n",
    "\n",
    "`# Modify each layer: remove the activation from the layer itself.`  \n",
    "`# Set use_bias=False since batch norm will play the role of biases.`  \n",
    "`tf.keras.layers.Conv2D(..., use_bias=False),`  \n",
    "`# Batch norm goes between the layer and its activation.`  \n",
    "`# The scale factor can be turned off for Relu activation.`  \n",
    "`tf.keras.layers.BatchNormalization(scale=False, center=True),`  \n",
    "`# Finish with the activation.`  \n",
    "`tf.keras.layers.Activation('relu'),`  \n",
    "\n",
    "\n",
    "Wie steht es nun um die Genauigkeit?\n",
    "\n",
    "<img src=\"images/teke48.png\" width=\"800\">\n",
    "\n",
    "Mit ein wenig Optimierungsarbeit (BATCH_SIZE=64, Parameter für die Lernrate 0,666, Dropout-Rate auf der dense Layer 0,3) und ein wenig Glück kann man 99,5 % erreichen. Die Anpassungen der Lernrate und der Dropout-Rate wurden gemäß den \"Best Practices\" für die Verwendung der Batch-Norm vorgenommen:\n",
    "\n",
    "* Die Batch normalization hilft neuronalen Netzen bei der Konvergenz und ermöglicht in der Regel ein schnelleres Training.\n",
    "* Die Batch normalization ist ein Regularisierer. In der Regel können Sie die Dropout-Menge verringern oder sogar ganz auf Dropout verzichten.\n",
    "\n",
    "Das Lösungsnotizbuch hat einen Trainingslauf von 99,5 %:   \n",
    "  \n",
    "<img src=\"images/teke00.png\" width=\"20\" height=\"20\">  [keras_05_mnist_batch_norm.ipynb](keras_05_mnist_batch_norm.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620c944-92a6-4d84-812d-b29afbc14c39",
   "metadata": {},
   "source": [
    "## 14. Train in the cloud on powerful hardware: AI Platform\n",
    "siehe  \n",
    "https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist#13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7343dd14-07fc-4502-a221-7b9aa7cfbe99",
   "metadata": {},
   "source": [
    "## 15. Congratulations!\n",
    "Sie haben Ihr erstes neuronales Netz erstellt und es bis zu einer Genauigkeit von 99 % trainiert. Die dabei erlernten Techniken sind nicht spezifisch für den MNIST-Datensatz, sondern werden bei der Arbeit mit neuronalen Netzen häufig verwendet. Als Abschiedsgeschenk gibt es hier die \"Cliff's Notes\" für das Labor in Cartoonform. Sie können sie benutzen, um sich an das Gelernte zu erinnern:\n",
    "<img src=\"images/teke50.png\" width=\"800\">\n",
    "\n",
    "## 16. Nächste Schritte\n",
    "* Nach \"fully-connected and convolutional\" Netzwerken sollten Sie sich [rekurrente neuronale Netzwerke ansehen](https://www.youtube.com/watch?v=fTUwdXUFfI8).\n",
    "* Um Ihr Training oder Ihre Inferenzen in der Cloud auf einer verteilten Infrastruktur durchzuführen, lohnt sich [Google Cloud AI Platform](https://cloud.google.com/vertex-ai).\n",
    "* Das sollten Sie sich ruhig auch mal als Fortsetzung des gelernten ansehen. [Keras MNIST TPU end-to-end](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/01_MNIST_TPU_Keras.ipynb#scrollTo=qhdz68Xm3Z4Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370bc19-c523-48ef-bd0c-2addb054257d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
